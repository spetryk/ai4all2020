{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/spetryk/ai4all2020/blob/master/2-Exploring%20the%20fake%20image%20space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to explore the input space to a generator\n",
    "Inspired by [this](https://machinelearningmastery.com/how-to-interpolate-and-perform-vector-arithmetic-with-faces-using-a-generative-adversarial-network/) tutorial by Jason Brownlee.\n",
    "\n",
    "Generators learn to map points in the space of **random noise** to the space of **images**. We call this random-noise-space the \"latent\" space, latent meaning \"hidden\". It's hidden because to us, the noise doesn't have any meaning - it's literally random numbers. It only has meaning to the generator model, which has been trained to create meaning out of these random numbers.\n",
    "\n",
    "\n",
    "So, what does it mean to \"explore\" the latent space? It's all about vector arithmetic. If you have two vectors (or points in space) you can draw a line between them, and find the midpoint.\n",
    "\n",
    "For our generator, those two points in space are two different images. We can \"draw a line\" between the two images in latent space and find the midpoint. What happens if we now pass the midpoint through the generator? We should get the \"average\" of the two images!\n",
    "\n",
    "\n",
    "Let's try it out. First, we'll load up a generator that has already been trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Google CoLab to set everything up\n",
    "! git clone https://github.com/spetryk/ai4all2020.git\n",
    "%cd ai4all2020/\n",
    "%mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tools import *\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import PillowWriter\n",
    "\n",
    "# from https://stackoverflow.com/questions/51512141/how-to-make-matplotlib-saved-gif-looping\n",
    "class LoopingPillowWriter(PillowWriter):\n",
    "    def finish(self):\n",
    "        self._frames[0].save(\n",
    "            self._outfile, save_all=True, append_images=self._frames[1:],\n",
    "            duration=int(1000 / self.fps), loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 100\n",
    "generator  = Generator(noise_size)\n",
    "generator_parameters = torch.load('saved_models/pretrained_generator', map_location='cpu')\n",
    "generator.load_state_dict(generator_parameters['net_state_dict'])\n",
    "print('Loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll choose two random points in the latent space to interpolate between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise1 = torch.randn(1,noise_size,1,1)\n",
    "noise2 = torch.randn(1,noise_size,1,1)\n",
    "\n",
    "# Pass noise through generator and visualize the images it creates\n",
    "image1 = generator(noise1)\n",
    "image2 = generator(noise2)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "for column in range(2):\n",
    "    ax[column].axis('off')\n",
    "\n",
    "ax[0].set_title('Image 1')\n",
    "ax[1].set_title('Image 2')\n",
    "ax[0].imshow(visualize(image1[0].detach()))\n",
    "ax[1].imshow(visualize(image2[0].detach()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating \"midway\" image\n",
    "\n",
    "We now have our noise vectors, noise1 and noise2. Let's do the following:\n",
    "\n",
    "1. Calculate the midway point\n",
    "2. Pass it through the generator\n",
    "3. Visualize the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the midway point\n",
    "midway_point = # TODO\n",
    "\n",
    "midway_image = # TODO\n",
    "\n",
    "\n",
    "# Plot the images\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "for column in range(3):\n",
    "    ax[column].axis('off')\n",
    "\n",
    "ax[0].set_title('Image 1')\n",
    "ax[1].set_title('Midway image')\n",
    "ax[2].set_title('Image 2')\n",
    "\n",
    "ax[0].imshow(visualize(image1[0].detach()))\n",
    "ax[1].imshow(visualize(midway_image[0].detach()))\n",
    "ax[2].imshow(visualize(image2[0].detach()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks cool! (hopefully you are impressed..)\n",
    "\n",
    "\n",
    "But wait - there is a whole **line** of points between Image 1 and Image 2. Right now, we're only visualizing the middle point. Which brings us to:\n",
    "\n",
    "### Transitioning smoothly between images\n",
    "\n",
    "You know how the motion in a video looks like it's smooth, but it's really just a bunch of frames playing one after another? We'll do the same thing here to make a smooth interpolation between Image 1 and 2.\n",
    "\n",
    "To code this up, we'll define the number of frames we want, calculate each frame, put them into a list, and loop through the list to create a video.\n",
    "\n",
    "Hint: [This function](https://pytorch.org/docs/master/generated/torch.linspace.html) will be helpful!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 20\n",
    "\n",
    "# Initialize frames to empty list. We'll add on to it each iteration of the loop.\n",
    "frames = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_frames):\n",
    "    # Calculate what each frame should be\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize progression\n",
    "\n",
    "# Hack: to make gif go from A -> B -> A,\n",
    "# add a backwards list to the end of the list\n",
    "frames_viz = frames + frames[::-1][1:]\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(visualize(image[0].detach()), animated=True)] for image in frames_viz]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=100, repeat_delay=0, blit=True)\n",
    "#ani.save('interpolation.gif', writer=LoopingPillowWriter(fps=20))\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Add and subtract features\n",
    "\n",
    "With vector arithmetic, we can go beyond interpolating between two images. If the generator is trained well, then somewhere in the latent space is the part that means \"smiling\", or \"man\", or \"has mustache\", etc. By adding and subtracting the latent vectors, we can carefully add and subtract these various features from images.\n",
    "\n",
    "![vector image](resources/latent-image-example.png)\n",
    "\n",
    "The tricky part with the GAN we've trained is that we can't say \"here's an image of a face, find the noise that would generate it\". We can only guess-and-check by generating a bunch of noise, seeing what the output images are, and selecting the vectors we want to add and subtract by hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "#noise = torch.randn(num_samples, noise_size,1,1)\n",
    "noise = torch.load('saved_arrays/noise')\n",
    "\n",
    "images = []\n",
    "for i in tqdm(range(num_samples)):\n",
    "    image = generator(noise[i].unsqueeze(0))\n",
    "    images.append(generator(noise))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(10,10,figsize=(20,20))\n",
    "for row in range(10):\n",
    "    for column in range(10):\n",
    "        ax[row, column].axis('off')\n",
    "       \n",
    "row = 0\n",
    "column = 0\n",
    "for i in range(num_samples):\n",
    "    image = visualize(images[0][i].detach())\n",
    "    \n",
    "    ax[row, column].set_title(i)\n",
    "    ax[row, column].imshow(image)\n",
    "\n",
    "    column += 1\n",
    "    if column == 10:\n",
    "        column = 0\n",
    "        row += 1\n",
    "        \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which images you want to use\n",
    "\n",
    "smiling_woman  = noise[99]\n",
    "neutral_woman  = noise[98]\n",
    "neutral_man    = noise[94]\n",
    "\n",
    "smiling_man = # TODO fill in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = generator(smiling_man.unsqueeze(0))\n",
    "\n",
    "# Plot the images\n",
    "fig, ax = plt.subplots(1,4,figsize=(15,5))\n",
    "for column in range(4):\n",
    "    ax[column].axis('off')\n",
    "\n",
    "ax[0].set_title('Smiling Woman', fontsize=18)\n",
    "ax[1].set_title('- Neutral Woman', fontsize=18)\n",
    "ax[2].set_title('+ Neutral Man', fontsize=18)\n",
    "ax[3].set_title('= Smiling Man', fontsize=18)\n",
    "\n",
    "ax[0].imshow(visualize(images[0][99].detach()))\n",
    "ax[1].imshow(visualize(images[0][98].detach()))\n",
    "ax[2].imshow(visualize(images[0][94].detach()))\n",
    "ax[3].imshow(visualize(new_image[0].detach()))\n",
    "#plt.savefig('smiling_man.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(noise, 'saved_arrays/noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
