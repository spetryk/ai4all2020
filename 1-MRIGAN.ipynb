{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/spetryk/ai4all2020/blob/master/1-MRIGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GAN on Brain MRI Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello! In this notebook we'll train a GAN to generate fake MRI brain scans. We'll set up the dataset and neural networks, then train the GAN and see how the output changes over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Google CoLab to set everything up\n",
    "! git clone https://github.com/spetryk/ai4all2020.git\n",
    "%cd ai4all2020/\n",
    "%mkdir mridata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Functions for training neural network\n",
    "from mri_tools import Generator, Discriminator, get_brainomics_dataloader, update\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "# Functions for visualizations\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import PillowWriter\n",
    "\n",
    "# from https://stackoverflow.com/questions/51512141/how-to-make-matplotlib-saved-gif-looping\n",
    "class LoopingPillowWriter(PillowWriter):\n",
    "    def finish(self):\n",
    "        self._frames[0].save(\n",
    "            self._outfile, save_all=True, append_images=self._frames[1:],\n",
    "            duration=int(1000 / self.fps), loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "\n",
    "To train a GAN, we need to keep giving it examples of what real images should look like. Right now, we have a folder with all of these images. How do we go from images saved as files on our computer to images in number-form that are ready for a neural network to use?\n",
    "\n",
    "Fortunately, the machine learning framework that we are using called PyTorch can do this for us. We've placed most of the PyTorch code for this in the file **tools.py** and **dataloaders.py**, but this is what it's doing behind the scenes:\n",
    "\n",
    "1. Reads each image file into a list of numbers that specify the color at each pixel\n",
    "2. Processes each image to the correct size and range of values\n",
    "3. Creates a **data loader**, which keeps track of which images the GAN used already so it can keep giving it new ones in each round of training\n",
    "\n",
    "The code below creates the data loader and plots some sample images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where images are stored\n",
    "dataroot = \"./mri_data\"\n",
    "\n",
    "# Batch size: number of images the GAN sees in one round of training\n",
    "batch_size = 64\n",
    "\n",
    "dataloader = get_brainomics_dataloader(dataroot, batch_size)\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to the generator\n",
    "\n",
    "Remember that the input to the generator model is just a random bunch of numbers.\n",
    "Let's see what that looks like - it'll help you appreciate how difficult this problem is!\n",
    "\n",
    "Note: The actual input is 1-dimensional - just a list of numbers. We'll create noise in the shape of a square just for visualization. The function we will use is [here](https://pytorch.org/docs/master/generated/torch.randn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = # TODO fill in, using the torch.randn function\n",
    "plt.imshow(noise, cmap='gray')\n",
    "plt.title('Example of noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the models\n",
    "\n",
    "\n",
    "Let's now create the generator and discriminator models. If you would like to, you can look at the network structure defined in the **tools.py** file and change the model. You can also change the training settings in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of noise vector (i.e. size of generator input)\n",
    "noise_size = 100\n",
    "\n",
    "# Use a GPU if available, or you can choose to use the CPU by setting use_cpu = True\n",
    "use_cpu = False\n",
    "device = 'cuda:0' if (torch.cuda.is_available() and not use_cpu) else 'cpu'\n",
    "print('Using device {}\\n'.format(device))\n",
    "\n",
    "img_size = (240, 128, 1)\n",
    "generator     = Generator(img_size=img_size, latent_dim=noise_size).to(device)\n",
    "discriminator = Discriminator(img_size=img_size).to(device)\n",
    "\n",
    "# Initialize the weights of the networks\n",
    "#generator.apply(initialize_weights)\n",
    "#discriminator.apply(initialize_weights)\n",
    "\n",
    "# Print out the network structure\n",
    "print('Generator structure:')\n",
    "print(generator)\n",
    "print('\\n')\n",
    "\n",
    "print('Discriminator structure:')\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "number_of_epochs = 5\n",
    "learning_rate    = 0.0001\n",
    "\n",
    "# Create optimizers, which are functions that will update the models for us\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.9, 0.99))\n",
    "generator_optimizer     = optim.Adam(generator.parameters(),     lr=learning_rate, betas=(0.9, 0.99))\n",
    "\n",
    "# Create batch of noise that we will use to visualize\n",
    "# the progression of the generator\n",
    "shape = (64, noise_size, 1, 1)\n",
    "fixed_noise = torch.randn(shape, device=device)\n",
    "\n",
    "# Create folder to save models in case training is interrupted\n",
    "save_dir = './mri_saved_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Write functions to calculate losses for the discriminator and generator. A loss function indicates how poorly the generator or discriminator is doing. So a high loss value for the generator means that it is doing a poor job fooling the discriminator, and a high loss value for the discriminator means that it is not guessing which images are real or fake correctly.\n",
    "## Discriminator Loss\n",
    "The discriminator should get credit for predicting \"real\" (i.e. predicting 1) on real images, and for predicting \"fake\" (i.e. predicting 0) on fake images. To make this calculation, we first need to see what the discriminator predicts on the real images, and then see what the discriminator predicts on the fake images. We use these predictions to compute the loss for each, and then we sum up the two losses.\n",
    "## Generator Loss\n",
    "The generator should get credit when the discriminator predicts \"real\" (i.e. predicts 1) on an image that the generator predicted. To figure this out, we need to see what the discriminator predicts on the generator-produced images, and then we use that prediction to compute the loss.\n",
    "## Useful Functions\n",
    "To generate fake images with the generator, you can simply call the generator as a function, passing in the input noise:\n",
    "```\n",
    "generated_images = generator(noise)\n",
    "```\n",
    "To predict whether an images are real or fake using the discriminator, you can do something similar:\n",
    "```\n",
    "predictions = discriminator(images)\n",
    "```\n",
    "To calculate the loss function, you can use a function called `calculate_loss`, which takes the discriminator's predictions, as well as the ground truth labels. For example, if the discriminator predicts `[0.2, 0.8, 0.9]` for three real images, you could compute the discriminator's loss by running\n",
    "```\n",
    "loss = calculate_loss([0.2, 0.8, 0.9], [1, 1, 1])\n",
    "```\n",
    "To figure out how to compute the correct loss values, keep in mind that `calculate_loss` will return a small value (i.e. the model is doing well) if the predictions and the true labels match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "sample_generator_images = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "# Keep track of discriminator performance\n",
    "probs_real = []\n",
    "probs_fake = []\n",
    "\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(number_of_epochs):\n",
    "    print('****** Starting epoch {} ******'.format(epoch))\n",
    "    \n",
    "    # For each batch in the dataloader\n",
    "    for iteration, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    \n",
    "        # Parse data into the correct format for training\n",
    "        real_images = data.cuda()\n",
    "        noise = torch.randn(real_images.size(0), noise_size, 1, 1, device=\"cuda\")\n",
    "\n",
    "        ############################\n",
    "        # (1) Update Discriminator\n",
    "        ###########################\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # Train discriminator on all-real batch\n",
    "        predictions_on_real = discriminator(real_images)\n",
    "        loss_on_real = -1 * predictions_on_real.mean()\n",
    "        \n",
    "        # Train discriminator on all-fake batch\n",
    "        fake_images         = generator(noise)\n",
    "        predictions_on_fake = discriminator(fake_images.detach())\n",
    "        loss_on_fake = predictions_on_fake.mean()\n",
    "        \n",
    "        extra_loss = gradient_penalty(discriminator, real_images, generated_images)\n",
    "        \n",
    "        # Update the discriminator model\n",
    "        discriminator_loss = loss_on_real + loss_on_fake + extra_loss\n",
    "        update(discriminator_optimizer, discriminator_loss)\n",
    "        \n",
    "\n",
    "        ############################\n",
    "        # (2) Update Generator\n",
    "        ###########################\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        # Try to fool discriminator into predicting that fake images are real\n",
    "        predictions_on_fake = discriminator(fake_images)\n",
    "        generator_loss      = -1 * predictions_on_fake.mean()\n",
    "        update(generator_optimizer, generator_loss)\n",
    "        \n",
    "        # Output training stats every 100 iterations\n",
    "        if iteration % 100 == 0:\n",
    "            print('Iteration %d.\\tLoss_D: %.4f\\tLoss_G: %.4f\\tProb real: %.4f\\tProb fake: %.4f'\n",
    "                  % (iteration,\n",
    "                     discriminator_loss.item(),\n",
    "                     generator_loss.item(),\n",
    "                     predictions_on_real.mean().item(),\n",
    "                     1 - predictions_on_fake.mean().item()))\n",
    "            \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(generator_loss.item())\n",
    "        D_losses.append(discriminator_loss.item())\n",
    "        probs_real.append(predictions_on_real.mean().item())\n",
    "        probs_fake.append(1 - predictions_on_fake.mean().item())\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == number_of_epochs-1) and (iteration == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).detach().cpu()\n",
    "            samples = vutils.make_grid(fake, padding=2, normalize=True)\n",
    "            sample_generator_images.append(samples)\n",
    "            \n",
    "        iters += 1\n",
    "        \n",
    "        \n",
    "    # Save models in case training is interrupted\n",
    "    print('Saving models to {}'.format(save_dir))\n",
    "    save_model(discriminator, discriminator_optimizer, epoch, os.path.join(save_dir, 'discriminator_epoch{}'.format(epoch)))\n",
    "    save_model(generator,     generator_optimizer,     epoch, os.path.join(save_dir, 'generator_epoch{}'.format(epoch)))\n",
    "\n",
    "    \n",
    "    # Show some sample generated images after each epoch\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(sample_generator_images[-1], (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in sample_generator_images]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "ani.save('training.gif', writer=LoopingPillowWriter(fps=20))\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"Generator\")\n",
    "plt.plot(D_losses,label=\"Discriminator\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Discriminator predictions on real and fake data\")\n",
    "plt.plot(probs_real,label=\"Probability that real is real\")\n",
    "plt.plot(probs_fake,label=\"Probability that fake is fake\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Exercise 2\n",
    "Sometimes, the discriminator has a harder time detecting fake images than the generator does creating fake images. When this happens, the generator can \"win\", and then learning stops. To address this, one common practice is to update the discriminator several times between each time that you update the generator.\n",
    "Implement this feature in the above training loop, allowing for a variable number of discriminator steps between each generator step depending on a variable `DISCRIMINATOR_STEPS_PER_GENERATOR_STEP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
