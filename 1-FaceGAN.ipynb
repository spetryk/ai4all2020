{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/spetryk/ai4all2020/blob/master/1-FaceGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by [this](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) tutorial.\n",
    "\n",
    "Hello! In this notebook we'll train a GAN to generate images of faces. We'll set up the dataset and neural networks, then train the GAN and see how the output changes over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab\n",
    "! git clone https://github.com/spetryk/ai4all2020.git\n",
    "%cd ai4all2020/\n",
    "%mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Functions for training neural network\n",
    "from tools import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "# Functions for visualizations\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import PillowWriter\n",
    "\n",
    "# from https://stackoverflow.com/questions/51512141/how-to-make-matplotlib-saved-gif-looping\n",
    "class LoopingPillowWriter(PillowWriter):\n",
    "    def finish(self):\n",
    "        self._frames[0].save(\n",
    "            self._outfile, save_all=True, append_images=self._frames[1:],\n",
    "            duration=int(1000 / self.fps), loop=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**How to download the data:** Download the data from [this link.](https://drive.google.com/file/d/1Ob0b3ssQ9RN49m74nsedeQZOMytPVRPd/view?usp=sharing) Then, move it into the **data/** folder, so the file structure is **data/faces/...all-the-faces.jpg...**\n",
    "\n",
    "To train a GAN, we need to keep giving it examples of what real images should look like. Right now, we have a folder with all of these images. How do we go from images saved as files on our computer to images in number-form that are ready for a neural network to use?\n",
    "\n",
    "Fortunately, the machine learning framework that we are using called PyTorch can do this for us. We've placed most of the PyTorch code for this in the file **tools/data.py**, but this is what it's doing behind the scenes:\n",
    "\n",
    "1. Reads each image file into a list of numbers that specify the color at each pixel\n",
    "2. Processes each image to the correct size and range of values\n",
    "3. Creates a **data loader**, which keeps track of which images the GAN used already so it can keep giving it new ones in each round of training\n",
    "\n",
    "The code below creates the data loader and plots some sample images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where images are stored\n",
    "dataroot = \"data/faces\"\n",
    "\n",
    "# Batch size: number of images the GAN sees in one round of training\n",
    "batch_size = 128\n",
    "\n",
    "# Size of images, in pixels (they will be square)\n",
    "image_size = 64\n",
    "\n",
    "dataloader = get_dataloader(dataroot, image_size, batch_size)\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to the generator\n",
    "\n",
    "Remember that the input to the generator model is just a random bunch of numbers.\n",
    "Let's see what that looks like - it'll help you appreciate how difficult this problem is!\n",
    "\n",
    "Note: The actual input is 1-dimensional - just a list of numbers. We'll create noise in the shape of a square just for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noise = torch.randn(64,64)\n",
    "plt.imshow(noise, cmap='gray')\n",
    "plt.title('Example of noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the models\n",
    "\n",
    "\n",
    "Let's now create the generator and discriminator models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of noise vector (i.e. size of generator input)\n",
    "noise_size = 100\n",
    "\n",
    "# Use a GPU if available, or you can choose to use the CPU by setting use_cpu = True\n",
    "use_cpu = False\n",
    "device = 'cuda:0' if (torch.cuda.is_available() and not use_cpu) else 'cpu'\n",
    "print('Using device {}\\n'.format(device))\n",
    "\n",
    "\n",
    "generator     = Generator(noise_size).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Initialize the weights of the networks\n",
    "generator.apply(initialize_weights)\n",
    "discriminator.apply(initialize_weights)\n",
    "\n",
    "# Print out the network structure\n",
    "print('Generator structure:')\n",
    "print(generator)\n",
    "print('\\n')\n",
    "\n",
    "print('Discriminator structure:')\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "number_of_epochs = 5\n",
    "learning_rate    = 0.0002\n",
    "\n",
    "\n",
    "# Create optimizers, which are functions that will update the models for us\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "generator_optimizer     = optim.Adam(generator.parameters(),     lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# Create batch of noise that we will use to visualize\n",
    "# the progression of the generator\n",
    "fixed_noise = torch.randn(64, noise_size, 1, 1, device=device)\n",
    "\n",
    "# Create folder to save models in case training is interrupted\n",
    "save_dir = './saved_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "sample_generator_images = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "# Keep track of discriminator performance\n",
    "probs_real = []\n",
    "probs_fake = []\n",
    "\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(number_of_epochs):\n",
    "    print('****** Starting epoch {} ******'.format(epoch))\n",
    "    \n",
    "    # For each batch in the dataloader\n",
    "    for iteration, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "    \n",
    "        # Parse data into the correct format for training\n",
    "        real_images, labels_real, labels_fake, noise = format_data(data, device, noise_size)\n",
    "        labels_real.fill_(0.9)\n",
    "        labels_fake.fill_(0.1)\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update Discriminator\n",
    "        ###########################\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # Train discriminator on all-real batch\n",
    "        predictions_on_real = discriminator(real_images)\n",
    "        loss_on_real        = calculate_loss(predictions_on_real, labels_real)\n",
    "        \n",
    "        # Train discriminator on all-fake batch\n",
    "        fake_images         = generator(noise)\n",
    "        predictions_on_fake = discriminator(fake_images.detach())\n",
    "        loss_on_fake        = calculate_loss(predictions_on_fake, labels_fake)\n",
    "        \n",
    "        # Update the discriminator model\n",
    "        discriminator_loss = loss_on_real + loss_on_fake\n",
    "        update(discriminator_optimizer, discriminator_loss)\n",
    "        \n",
    "\n",
    "        ############################\n",
    "        # (2) Update Generator\n",
    "        ###########################\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        # Try to fool discriminator into predicting that fake images are real\n",
    "        predictions_on_fake = discriminator(fake_images)\n",
    "        labels_real.fill_(1.0)\n",
    "        generator_loss      = calculate_loss(predictions_on_fake, labels_real)\n",
    "        update(generator_optimizer, generator_loss)\n",
    "\n",
    "        # Output training stats every 100 iterations\n",
    "        if iteration % 100 == 0:\n",
    "            print('Iteration %d.\\tLoss_D: %.4f\\tLoss_G: %.4f\\tProb real: %.4f\\tProb fake: %.4f'\n",
    "                  % (iteration,\n",
    "                     discriminator_loss.item(),\n",
    "                     generator_loss.item(),\n",
    "                     predictions_on_real.mean().item(),\n",
    "                     1 - predictions_on_fake.mean().item()))\n",
    "            \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(generator_loss.item())\n",
    "        D_losses.append(discriminator_loss.item())\n",
    "        probs_real.append(predictions_on_real.mean().item())\n",
    "        probs_fake.append(1 - predictions_on_fake.mean().item())\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == number_of_epochs-1) and (iteration == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise).detach().cpu()\n",
    "            samples = vutils.make_grid(fake, padding=2, normalize=True)\n",
    "            sample_generator_images.append(samples)\n",
    "            \n",
    "        iters += 1\n",
    "        \n",
    "        \n",
    "    # Save models in case training is interrupted\n",
    "    print('Saving models to {}'.format(save_dir))\n",
    "    save_model(discriminator, discriminator_optimizer, epoch, os.path.join(save_dir, 'discriminator_epoch{}'.format(epoch)))\n",
    "    save_model(generator,     generator_optimizer,     epoch, os.path.join(save_dir, 'generator_epoch{}'.format(epoch)))\n",
    "\n",
    "    \n",
    "    # Show some sample generated images after each epoch\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(sample_generator_images[-1], (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in sample_generator_images]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "ani.save('training.gif', writer=LoopingPillowWriter(fps=20))\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"Generator\")\n",
    "plt.plot(D_losses,label=\"Discriminator\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Discriminator predictions on real and fake data\")\n",
    "plt.plot(probs_real,label=\"Probability that real is real\")\n",
    "plt.plot(probs_fake,label=\"Probability that fake is fake\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
