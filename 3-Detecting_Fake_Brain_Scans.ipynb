{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/spetryk/ai4all2020/blob/master/3-Detecting_Fake_Brain_Scans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Google CoLab to set everything up\n",
    "! git clone https://github.com/spetryk/ai4all2020.git\n",
    "%cd ai4all2020/\n",
    "%mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Functions for training neural network\n",
    "from tools import *\n",
    "from scans_utils import MRIDataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "# Functions for visualizations\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "The dataset we're using consists of real and fake MRI brain scans. The real brain scans come from a dataset called Brainomics, downloadable here: https://osf.io/vhtf6/files/. To make the fake brain scans, I trained a GAN much like we did yesterday.\n",
    "\n",
    "When you run the next cell for the first time, it will take some time to download the ~1GB dataset.\n",
    "\n",
    "Given a `dataset` variable, you can access the ith image and the label simply:\n",
    "```\n",
    "image, label = dataset[i]\n",
    "```\n",
    "\n",
    "You can compute the number of data points in a dataset by calling `len(dataset)`, and if you want to see what an `image` looks like, you can run\n",
    "```\n",
    "plt.matshow(image)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MRIDataset(\"data\", train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "val_dataset = MRIDataset(\"data\", train=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Inspecting the Data\n",
    "\n",
    "It's always important to understand what your dataset looks like, since many real-world datasets have oddities that can affect your machine learning algorithms. Here are a few simple things you might want to look into:\n",
    "\n",
    "* How many MRI images are in the dataset?\n",
    "* How many images are in the training set, and how many are in the validation set? Is this a good ratio for this dataset, and why might we want to use a different ratio?\n",
    "* A dataset has a balanced class distribution if there are the same number of images in each class (here, real and fake). Unbalanced datasets are more difficult to train on, since the model can learn how to do well on only the majority class. Is this dataset balanced?\n",
    "* If we use a classifier that always guesses \"fake\" no matter what image you present it with, what percent accuracy will that classifier get? What if the classifier guesses randomly between \"real\" and \"fake\"?\n",
    "* What is the mean pixel value of the real images? What is the mean pixel value of the fake images?\n",
    "* If we use a classifier that distinguishes between real and fake images by just looking at the mean pixel value of the image, what accuracy will that classifier get?\n",
    "\n",
    "You may notice that some of the fake images in this dataset do not look very realistic. This is because I trained a single GAN without fiddling with it much, and it only trained for about one day on cheap hardware. As you saw in the previous notebook, GANs can produce highly realistic images if trained with enough computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[1]\n",
    "print(\"Label: {} (i.e. '{}'')\".format(label, \"real\" if label else \"fake\"))\n",
    "plt.matshow(image)\n",
    "plt.show()\n",
    "\n",
    "image, label = train_dataset[11]\n",
    "print(\"Label: {} (i.e. '{}'')\".format(label, \"real\" if label else \"fake\"))\n",
    "plt.matshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Build your model\n",
    "A neural network consists of a sequence of layers: the input (in this case an image that we need to detect as real or fake) passes to the first layer, and then the output of the first layer is used as the input of the second layer, etc. At the very end, the last layer should output a single number that indicates the model's guess: a number close to 0 means the model thinks the image is fake, and a number close to 1 means the model thinks the image is real.\n",
    "\n",
    "There are many different types of neural network layers. The simplest is called a *linear* layer. A linear layer multiplies every number in the input by some weight, which is adjusted during training, and then it sums up the result of all those multiplications. We want the model to predict something close to 0 to indicate \"fake,\" and something close to 1 to indicate \"real.\" However, the output of a linear layer can be any number. Therefore, we use a \"sigmoid\" function to squish the linear layer's output into the range (0,1). A classifier with a single linear layer can be created in PyTorch as follows:\n",
    "```\n",
    "model = nn.Sequential(nn.Flatten(),\n",
    "                      nn.Linear(image_shape[0] * image_shape[1], 1),\n",
    "                      nn.Sigmoid())\n",
    "```\n",
    "where `image_shape` is the shape, in pixels, of an individual image. Try out this model, or modify it in any way you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_shape is the number of pixels wide and tall each scan is\n",
    "image_shape = (120, 64)\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(),\n",
    "                      nn.Linear(image_shape[0] * image_shape[1], 1),\n",
    "                      nn.Sigmoid())\n",
    "\n",
    "# set up the loss function and optimizer\n",
    "calculate_loss = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Fill in the Evaluation Loop\n",
    "This function measures the performance of the input model on the input dataset. Fill in the TODOs.\n",
    "To calculate the loss function, you can use a function called `calculate_loss`, which takes the model's predictions, as well as the ground truth labels. For example, if the model predicts `[0.2, 0.8, 0.9]` for three real images, you could compute the loss by running\n",
    "```\n",
    "loss = calculate_loss([0.2, 0.8, 0.9], [1, 1, 1])\n",
    "```\n",
    "To figure out how to compute the correct loss values, keep in mind that `calculate_loss` will return a small value (i.e. the model is doing well) if the predictions and the true labels match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    n_correct = 0\n",
    "    n_images = 0\n",
    "    losses = []\n",
    "    for images, labels in data_loader:\n",
    "        labels = labels.float()\n",
    "        \n",
    "        predictions =               # TODO use the model to make a prediction on images\n",
    "        loss =                      # TODO calculate the loss on this batch\n",
    "        \n",
    "        # save the loss from this iteration through the loop\n",
    "        losses.append(loss.item())\n",
    "        predictions = predictions.view(-1)\n",
    "        \n",
    "        number_correct_this_round = # TODO count how many images the model got correct\n",
    "\n",
    "        # keep track of the total number of images the model got correct, and the total number of images\n",
    "        n_correct += number_correct_this_round.item()\n",
    "        n_images += labels.numel()\n",
    "    print(\"Average Loss:\", np.mean(losses))\n",
    "    # calculate the accuracy as <number correct> / <total number of images>\n",
    "    print(\"Accuracy: {:3.2f}%\".format(n_correct / n_images * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Fill in the Training Loop\n",
    "As in the evaluation loop, we need to compute the model's predictions as well as the loss on each batch of data. The loss is then used to improve the model (this happens in `loss.backward()` and `optimizer.step()`). The training loop steps through all of the training data, improving the model at every iteration. It does this many times -- in this case for 10 \"epochs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall that the detector model is in a variable called `model`\n",
    "step = 0\n",
    "for epoch in range(10):\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        predictions = # TODO predict whether the brain scans in the images variable are real or fake\n",
    "        loss =        # TODO compute the loss on this batch\n",
    "        \n",
    "        # update the model by tweaking it to improve the loss a little bit\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print out the loss every once in a while\n",
    "        if step % 100 == 0:\n",
    "            print(\"loss:\", loss.item())\n",
    "        step += 1\n",
    "    # see how well the model does on the validation dataset\n",
    "    evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Analyze the Trained Model\n",
    "It's always a good idea to take a look at the trained model in order to understand where it does well and where it does poorly. Here are a few questions you might consider:\n",
    "* What is the final accuracy of the model on the validation data? What is the final accuracy of the model on the training data? Why is there a discrepancy?\n",
    "* What is the accuracy of the model on real images in the validation data? What about the accuracy on fake images? If these numbers are very different, why might that be?\n",
    "* What are some real images that the model classified as fake? Why do you think they were classified as fake? What about fake images that the model classified as real? Do those images look particularly realistic to you?\n",
    "* What might you change about the training procedure to improve performance? Should you train for more epochs? Larger learning rate? Different batch size?\n",
    "* What might you change about the model to improve performance? Should you add more layers? Different layers (what about convolutions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
